{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5 reader\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import scipy.optimize as opt\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from scipy.interpolate import griddata, interp1d\n",
    "import emcee\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "work_path = \"/home/shengduo/pylith-developer/build/debug/pylith-nonRegSlipLawWithVaryingB/examples/2d/InverseExp/\"\n",
    "h5_path = work_path + \"output/fault/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gaussian-regression related functions\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Pre-process the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# function train_GP\n",
    "class GP_predictor:\n",
    "    # Constructor\n",
    "    def __init__(self, \n",
    "                 input_set, \n",
    "                 observation_set, \n",
    "                 GPkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3)), \n",
    "                 n_optimizers = 9):\n",
    "        # Scale input data\n",
    "        self.input_set = [list(x) for x in input_set]\n",
    "        self.observation_set = [list(x) for x in observation_set]\n",
    "        self.input_dimension = len(self.input_set[0])\n",
    "        self.observation_dimension = len(self.observation_set[0])\n",
    "        self.trainset_length = len(self.input_set)\n",
    "        \n",
    "        self.input_scaler = preprocessing.StandardScaler()\n",
    "        self.input_scaler.fit(np.array(self.input_set))\n",
    "        \n",
    "        # Scale output data\n",
    "        self.observation_scaler = preprocessing.StandardScaler()\n",
    "        self.observation_scaler.fit(np.array(observation_set))\n",
    "        \n",
    "        # Fit Gaussian process\n",
    "        self.GP = GaussianProcessRegressor(kernel = GPkernel, n_restarts_optimizer = n_optimizers)\n",
    "        # self.GP = MyGPR(kernel = GPkernel, n_restarts_optimizer = n_optimizers, max_iter = max_iterations)\n",
    "        self.GP.fit(self.input_scaler.transform(np.array(self.input_set)), \n",
    "                    self.observation_scaler.transform(np.array(self.observation_set)))\n",
    "        \n",
    "    # Predict on a new input set\n",
    "    def predict(self, new_input_set):\n",
    "        # Predict new observation\n",
    "        new_observation = self.observation_scaler.inverse_transform(\n",
    "            self.GP.predict(\n",
    "                self.input_scaler.transform(np.array(list(new_input_set)).reshape([-1, self.input_dimension]))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return new_observation\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class RunABatch\n",
    "class RunABatch:\n",
    "    # Constructor\n",
    "    def __init__(self, input_set, work_path, FourierTerms = 16, distanceAbove = 2e-3, \n",
    "                 nOfQueryPts = 10, obsFlag = 'fault', fourierFlag = False):\n",
    "        # Initialize data paths and batch parameters\n",
    "        self.work_path = work_path\n",
    "        self.input_set = [tuple(i) for i in input_set]\n",
    "        self.h5_path = work_path + \"output/faultFiles/\"\n",
    "        self.frontsurf_path = work_path + \"output/frontsurfFiles/\"\n",
    "        self.FourierTerms = FourierTerms\n",
    "        self.distanceAbove = distanceAbove\n",
    "        self.nOfQueryPts = nOfQueryPts\n",
    "        self.fourierFlag = fourierFlag\n",
    "        \n",
    "        # Store all cases in the h5_path\n",
    "        self.existingCasesFile = self.h5_path + \"CaseList.csv\"\n",
    "        \n",
    "        # Flag for whether cases have been run\n",
    "        self.casesExcuted = False\n",
    "        \n",
    "        # Get existing cases\n",
    "        self.getExistingCasesOfInputSet()\n",
    "        \n",
    "        # Get input_set_toRun\n",
    "        self.input_set_toRun = list(set(self.input_set) - self.existingCases)\n",
    "        \n",
    "        # Run cases\n",
    "        self.runCases(self.input_set_toRun)\n",
    "        \n",
    "        # Get obsevations\n",
    "        # self.Observations = self.getObservations(self.input_set)\n",
    "        if obsFlag == 'fault':\n",
    "            self.Observations = self.getObservations(self.input_set, self.nOfQueryPts)\n",
    "        elif obsFlag == 'front':\n",
    "            self.Observations = self.getObservationsFrontSurf(self.input_set, self.nOfQueryPts, self.distanceAbove)\n",
    "        else:\n",
    "            self.Observations = self.getObservationsEveryWhere(self.input_set)\n",
    "            \n",
    "    # Inline function gets [A, B] list\n",
    "    def getABfwVw(self, fileName):\n",
    "        A_idx = fileName.find('A')\n",
    "        B_idx = fileName.find('B')\n",
    "        fw_idx = fileName.find('f')\n",
    "        Vw_idx = fileName.find('V')\n",
    "        slash_idx = fileName.find('-')\n",
    "        \n",
    "        # Change this part !! Before applying to new name convention\n",
    "        A = float(fileName[A_idx + 1 : B_idx - 1])\n",
    "        B = float(fileName[B_idx + 1 : fw_idx - 1])\n",
    "        fw = float(fileName[fw_idx + 2 : Vw_idx - 1])\n",
    "        Vw = float(fileName[Vw_idx + 2 : slash_idx])\n",
    "        \n",
    "        return (A, B, fw, Vw)\n",
    "    \n",
    "    \n",
    "    # Function get_existing_files_set\n",
    "    def getExistingCasesOfInputSet(self):\n",
    "        # Get all .h5 file names as a list\n",
    "        myPath = self.h5_path\n",
    "        onlyFiles = [f for f in listdir(myPath) if (isfile(join(myPath, f)) and f[-8 : ] == 'fault.h5')]\n",
    "        self.existingCases = set([self.getABfwVw(f) for f in onlyFiles])\n",
    "        \n",
    "    # Function runCases\n",
    "    def runCases(self, input_set):\n",
    "        shell_path = self.work_path + \"RunJobsJP.sh\"\n",
    "        shellRead = open(shell_path, 'r')\n",
    "        list_of_lines = shellRead.readlines()\n",
    "        shellRead.close()\n",
    "\n",
    "        AA = [ele[0] for ele in input_set]\n",
    "        BB = [ele[1] for ele in input_set]\n",
    "        FW = [ele[2] for ele in input_set]\n",
    "        VW = [ele[3] for ele in input_set]\n",
    "        \n",
    "        list_of_lines[9] = \"AA=\" + str(tuple(AA)).replace(',', '') + \"\\n\"\n",
    "        list_of_lines[10] = \"BB=\" + str(tuple(BB)).replace(',', '') + \"\\n\"\n",
    "        list_of_lines[11] = \"FW=\" + str(tuple(FW)).replace(',', '') + \"\\n\"\n",
    "        list_of_lines[12] = \"VW=\" + str(tuple(VW)).replace(',', '') + \"\\n\"\n",
    "\n",
    "        shellWrite = open(shell_path, 'w')\n",
    "        shellWrite.writelines(list_of_lines)\n",
    "        shellWrite.close()\n",
    "\n",
    "        # Run the cases\n",
    "        !source $shell_path\n",
    "        \n",
    "        self.casesExcuted = True\n",
    "        \n",
    "        # Return from shell\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Function getObservations for the input_set\n",
    "    def getObservations(self, input_set, nOfQueryPts):\n",
    "        # Initialize Observations\n",
    "        Observations = []\n",
    "        \n",
    "        # Check if the cases have been excuted\n",
    "        if self.casesExcuted == False:\n",
    "            return Observations\n",
    "        \n",
    "        # Rotation matrix Q\n",
    "        alpha = 29 / 180 * np.pi\n",
    "        Q = np.array([[np.cos(alpha), np.sin(alpha)], [-np.sin(alpha), np.cos(alpha)]])\n",
    "        \n",
    "        # VS start\n",
    "        VSstart = np.array([0.006354, 0.003522])\n",
    "        \n",
    "        # Loop through all Inputs\n",
    "        for input_ele in input_set:\n",
    "            # Open the file\n",
    "            h5_file = self.h5_path + \"A\" + str(input_ele[0]) + \"_B\" + str(input_ele[1]) \\\n",
    "                      + \"_fw\" + str(input_ele[2]) + \"_Vw\" + str(input_ele[3]) + \"-fault.h5\"\n",
    "                     \n",
    "            f = h5py.File(h5_file, 'r')\n",
    "\n",
    "            # Get time\n",
    "            times = np.array(f['time']).reshape([-1])\n",
    "            times = times - np.min(times)\n",
    "            nOfTSteps = times.shape[0]\n",
    "            \n",
    "            # Get coordinates\n",
    "            coords = np.array(f['geometry']['vertices']) - VSstart\n",
    "            Qcoords = coords @ Q.transpose()\n",
    "            XXs = Qcoords[:, 0]\n",
    "            \n",
    "            # Get Slip rates [time, nOfNodes, spaceDim]\n",
    "            SlipRates = np.array(f['vertex_fields']['slip_rate'])\n",
    "            SlipRatesMag = np.linalg.norm(SlipRates, ord = 2, axis = 2)\n",
    "            nOfNodes = SlipRatesMag.shape[1]\n",
    "            \n",
    "            xqs = 1e-3 * np.linspace(0., 45., nOfQueryPts)\n",
    "            \n",
    "            # Store the slip rates\n",
    "            slip_rate_func = interp1d(XXs, SlipRatesMag, kind = 'cubic')  # [nOfTSteps, nOfNodes]\n",
    "            \n",
    "            # Change slip rate x to [nOfNodes, nOfTSteps]\n",
    "            slip_rate_x = slip_rate_func(xqs).transpose()\n",
    "            \n",
    "#             # DEBUG LINES\n",
    "#             print('nOfTSteps: ', nOfTSteps)\n",
    "#             print('nOfNodes: ', nOfNodes)\n",
    "#             print('SlipRatesMag shape: ', SlipRatesMag.shape)\n",
    "#             print('slip_rate_x shape: ', slip_rate_x.shape)\n",
    "            \n",
    "            # Get the observations\n",
    "            if self.fourierFlag:\n",
    "                # Find the Fourier coefficients\n",
    "                FourierTerms = self.FourierTerms\n",
    "                T = np.max(times)\n",
    "\n",
    "                # Compute the Fourier terms\n",
    "                Ks = np.array(range(FourierTerms))\n",
    "                coskPiTt = np.cos(Ks.reshape([-1, 1]) * np.pi / T * times)\n",
    "                VxcoskPiTt = np.concatenate([coskPiTt * Vxi.reshape([1, -1]) for Vxi in slip_rate_x], 0)\n",
    "\n",
    "                # Compute the fourier coefficients\n",
    "                # print('time.shape: ', time.shape)\n",
    "                observation = np.trapz(VxcoskPiTt, x=times)\n",
    "                # print(\"observation shape: \", observation.shape)\n",
    "                # Append the result from this file\n",
    "                Observations.append(observation)\n",
    "            else:\n",
    "                # Find nFourier terms of values, evenly spaced in [0, T]\n",
    "                T = np.max(times)\n",
    "                tts = np.linspace(0., T, self.FourierTerms)\n",
    "                observation_func = interp1d(times, slip_rate_x)\n",
    "                observation = observation_func(tts).reshape([-1])\n",
    "                Observations.append(observation)\n",
    "                \n",
    "        Observations = np.array(Observations)\n",
    "        return Observations\n",
    "    \n",
    "    # Function getObservationsFrontSurf for the input_set\n",
    "    def getObservationsFrontSurf(self, input_set, nOfQueryPts, distanceAbove):\n",
    "        # Initialize Observations\n",
    "        Observations = []\n",
    "        \n",
    "        # Rotation matrix Q\n",
    "        alpha = 29 / 180 * np.pi\n",
    "        Q = np.array([[np.cos(alpha), np.sin(alpha)], [-np.sin(alpha), np.cos(alpha)]])\n",
    "        \n",
    "        # VS start\n",
    "        VSstart = np.array([0.006354, 0.003522])\n",
    "        \n",
    "        # Query points\n",
    "        distance_above = distanceAbove  # Distance above the interface\n",
    "        \n",
    "        # Set x_up query points\n",
    "        x_up = 1e-3 * np.linspace(0., 45., nOfQueryPts)\n",
    "        QueryPts_up = np.stack([x_up, distance_above * np.ones(x_up.shape)], axis = 1)\n",
    "        QueryPts_dn = np.stack([x_up, -distance_above * np.ones(x_up.shape)], axis = 1)\n",
    "        \n",
    "        # nOfNodes\n",
    "        nOfNodes = len(x_up)\n",
    "            \n",
    "        # Check if the cases have been excuted\n",
    "        if self.casesExcuted == False:\n",
    "            return Observations\n",
    "        \n",
    "        # Loop through all Inputs\n",
    "        for input_ele in input_set:\n",
    "            # Open the file\n",
    "            h5_file = self.frontsurf_path + \"A\" + str(input_ele[0]) + \"_B\" + str(input_ele[1]) \\\n",
    "                      + \"_fw\" + str(input_ele[2]) + \"_Vw\" + str(input_ele[3]) + \"-domain.h5\"\n",
    "                     \n",
    "            f = h5py.File(h5_file, 'r')\n",
    "            \n",
    "            # Get time\n",
    "            times = np.array(f['time']).reshape([-1])\n",
    "            times = times - np.min(times)\n",
    "            nOfTSteps = times.shape[0]\n",
    "\n",
    "            # Get coordinates\n",
    "            coords = np.array(f['geometry']['vertices']) - VSstart\n",
    "            Qcoords = coords @ Q.transpose()\n",
    "            \n",
    "            # Store the slip rates\n",
    "            slip_rate_x = np.zeros([nOfTSteps, nOfNodes])\n",
    "            \n",
    "            # Get Slip rates\n",
    "            velocity = np.array(f['vertex_fields']['velocity'])\n",
    "            Qvelocity = velocity @ Q.transpose()\n",
    "            \n",
    "            for i in range(nOfTSteps):\n",
    "                slip_rate_x[i, :] = - griddata(Qcoords, velocity[i, :, 0], QueryPts_up, method = 'cubic') \\\n",
    "                              + griddata(Qcoords, velocity[i, :, 0], QueryPts_dn, method = 'cubic')\n",
    "            slip_rate_x = slip_rate_x.transpose()\n",
    "            \n",
    "            # Get the observations\n",
    "            if self.fourierFlag:\n",
    "                # Find the Fourier coefficients\n",
    "                FourierTerms = self.FourierTerms\n",
    "                T = np.max(times)\n",
    "\n",
    "                # Compute the Fourier terms\n",
    "                Ks = np.array(range(FourierTerms))\n",
    "                coskPiTt = np.cos(Ks.reshape([-1, 1]) * np.pi / T * times)\n",
    "                VxcoskPiTt = np.concatenate([coskPiTt * Vxi.reshape([1, -1]) for Vxi in slip_rate_x], 0)\n",
    "\n",
    "                # Compute the fourier coefficients\n",
    "                # print('time.shape: ', time.shape)\n",
    "                observation = np.trapz(VxcoskPiTt, x=times)\n",
    "                # print(\"observation shape: \", observation.shape)\n",
    "                # Append the result from this file\n",
    "                Observations.append(observation)\n",
    "            \n",
    "            else:\n",
    "                # Find nFourier terms of values, evenly spaced in [0, T]\n",
    "                T = np.max(times)\n",
    "                tts = np.linspace(0., T, self.FourierTerms)\n",
    "                observation_func = interp1d(times, slip_rate_x)\n",
    "                observation = observation_func(tts).reshape([-1])\n",
    "                Observations.append(observation)\n",
    "        \n",
    "        Observations = np.array(Observations)\n",
    "        return Observations\n",
    "    \n",
    "    # Function getObservationsFrontSurf for the input_set\n",
    "    def getObservationsEveryWhere(self, input_set):\n",
    "        # Initialize Observations\n",
    "        Observations = []\n",
    "        \n",
    "        # Rotation matrix Q\n",
    "        alpha = 29 / 180 * np.pi\n",
    "        Q = np.array([[np.cos(alpha), np.sin(alpha)], [-np.sin(alpha), np.cos(alpha)]])\n",
    "        \n",
    "        # VS start\n",
    "        VSstart = np.array([0.006354, 0.003522])\n",
    "            \n",
    "        # Check if the cases have been excuted\n",
    "        if self.casesExcuted == False:\n",
    "            return Observations\n",
    "        \n",
    "        # Loop through all Inputs\n",
    "        for input_ele in input_set:\n",
    "            # Open the file\n",
    "            h5_file = self.frontsurf_path + \"A\" + str(input_ele[0]) + \"_B\" + str(input_ele[1]) \\\n",
    "                      + \"_fw\" + str(input_ele[2]) + \"_Vw\" + str(input_ele[3]) + \"-domain.h5\"\n",
    "                     \n",
    "            f = h5py.File(h5_file, 'r')\n",
    "            \n",
    "            # Get time\n",
    "            times = np.array(f['time']).reshape([-1])\n",
    "            times = times - np.min(times)\n",
    "            nOfTSteps = times.shape[0]\n",
    "\n",
    "            \n",
    "            # Get Slip rates\n",
    "            velocity = np.array(f['vertex_fields']['velocity'])\n",
    "            Qvelocity = velocity @ Q.transpose()\n",
    "            \n",
    "            # Collapse all measurements\n",
    "            slip_rate_x = Qvelocity.reshape([Qvelocity.shape[0], -1]).transpose\n",
    "            \n",
    "            # Find nFourier terms of values, evenly spaced in [0, T]\n",
    "            T = np.max(times)\n",
    "            tts = np.linspace(0., T, len(times))\n",
    "            observation_func = interp1d(times, slip_rate_x)\n",
    "            observation = observation_func(tts).reshape([-1])\n",
    "            Observations.append(observation)\n",
    "        \n",
    "        Observations = np.array(Observations)\n",
    "        return Observations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class BayersianInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bayersian Inv that solves a Bayersian inversion problem\n",
    "class BayersianInv:\n",
    "    # Constructor\n",
    "    def __init__(self, u_low, u_high, u, y, work_path, FourierTerms = 16, \n",
    "                 atol = 1.0e-6, si_eta = 0.5, n_samples = 20, MCMCsteps = 1000, save_path = \"./\", \n",
    "                 distanceAbove = 2e-3, nOfQueryPts = 10, obsFlag = 'fault', fourierFlag = False):\n",
    "        # Set X has to be compact in R^k\n",
    "        self.u_low = u_low\n",
    "        self.u_high = u_high\n",
    "        \n",
    "        # The true value of u, as well as the observation y to be inverted\n",
    "        self.u = u\n",
    "        self.y = y\n",
    "        \n",
    "        # Other parameters\n",
    "        self.input_dim = len(u_low)\n",
    "        self.output_dim = len(y)\n",
    "        self.work_path = work_path\n",
    "        self.FourierTerms = FourierTerms\n",
    "        self.atol = atol\n",
    "        self.si_eta = si_eta\n",
    "        self.n_samples = n_samples\n",
    "        self.MCMCsteps = MCMCsteps\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        # Keep record of distanceAbove and nOfQueryPts in the field of view\n",
    "        self.distanceAbove = distanceAbove\n",
    "        self.nOfQueryPts = nOfQueryPts\n",
    "        \n",
    "        # Get where the observations are from\n",
    "        self.obsFlag = obsFlag\n",
    "        self.fourierFlag = fourierFlag\n",
    "        \n",
    "        # Keep records of the sampled points and the corresponding observations after iteration\n",
    "        self.U = np.empty([0, self.input_dim])\n",
    "        self.O = np.empty([0, self.output_dim])\n",
    "        self.iterations = 0\n",
    "        \n",
    "        # Keep record of eta, MaxMinLenRatio, GaussianProcess Emulator, average error on the sampled points, \n",
    "        # and empirical mean and stdv of the posterior after each iteration\n",
    "        self.etas = []\n",
    "        self.maxMinDistRatio = []\n",
    "        self.GPs = []\n",
    "        self.avg_errors = []\n",
    "        self.mean = []\n",
    "        self.stdv = []\n",
    "        \n",
    "        # Maximum likelihood points\n",
    "        self.maxLikelihoodUs = []\n",
    "        self.maxLikelihoodUsPropL2Error = []\n",
    "        self.maxLikelihoodObsPropL2Error = []\n",
    "        \n",
    "    # Get the accumulative probability function\n",
    "    def log_prob(self, u, y):\n",
    "        # Apply hard constraints\n",
    "        u_reshape = u.reshape([-1, self.input_dim])\n",
    "        normal_idx = np.all(\n",
    "            np.concatenate(\n",
    "                [u_reshape >= self.u_low, u_reshape <= self.u_high], axis = 1\n",
    "            ), \n",
    "            axis = 1\n",
    "        )\n",
    "       \n",
    "        # First prior is uniform distribution\n",
    "        res = np.ones(len(u_reshape))\n",
    "        res[~normal_idx] = -np.inf\n",
    "        \n",
    "        # Add all posteriors in each iteration (since this is log of probability density)\n",
    "        if (np.sum(normal_idx) > 0):\n",
    "            for i in range(self.iterations):\n",
    "                res[normal_idx] += -0.5 / self.etas[i] ** 2 * (\n",
    "                    np.sum(\n",
    "                        (y - self.GPs[i].predict(u_reshape[normal_idx])) ** 2, \n",
    "                        axis = 1\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # Return the log_probability at the current iteration\n",
    "        return res\n",
    "    \n",
    "    # Compute statistics: sample and calculate mean and stdv\n",
    "    def compute_stats(self, n_samples, n_steps = 1_000):\n",
    "        # Sample for more points to update the empirical statistics\n",
    "        sampler = emcee.EnsembleSampler(n_samples, \n",
    "                                        self.input_dim, \n",
    "                                        self.log_prob, args=[y], \n",
    "                                        vectorize = True)\n",
    "\n",
    "        # Initialize uniformly as the starting point\n",
    "        p0 = np.random.uniform(size = [n_samples, self.input_dim]) * (self.u_high - self.u_low) + self.u_low\n",
    "\n",
    "        # Get the result\n",
    "        sampler.run_mcmc(p0, n_steps)\n",
    "        samples = sampler.get_last_sample().coords\n",
    "        self.mean.append(np.mean(samples, axis = 0))\n",
    "        self.stdv.append(np.std(samples, axis = 0))\n",
    "        \n",
    "        # Get maximum likelihood estimate\n",
    "        fun = lambda u: -self.log_prob(u, self.y)\n",
    "        newCenter = opt.minimize(fun, x0 = self.mean[-1], \n",
    "                                 bounds = [(self.u_low[i], self.u_high[i]) for i in range(len(self.u_low))]\n",
    "                                ).x\n",
    "        \n",
    "        self.maxLikelihoodUs.append(newCenter)\n",
    "        \n",
    "        self.maxLikelihoodUsPropL2Error.append(\n",
    "            np.linalg.norm(self.u - self.maxLikelihoodUs[-1]) \n",
    "            / np.linalg.norm(self.u)\n",
    "        )\n",
    "        self.maxLikelihoodObsPropL2Error.append(\n",
    "            np.linalg.norm(self.y - self.GPs[-1].predict(self.maxLikelihoodUs[-1])) \n",
    "            / np.linalg.norm(self.y)\n",
    "        )\n",
    "        \n",
    "    # Get average error of a batch\n",
    "    def get_avg_error_of_a_batch(self, myBatch):\n",
    "        return np.mean(np.sum((myBatch.Observations - self.y) ** 2, axis = 1))\n",
    "    \n",
    "    # Run one iteration\n",
    "    def runOneIteration(self, n_samples, n_stat_samples):\n",
    "        # Sample from the current distribution for u and get the current observations\n",
    "        sampler = emcee.EnsembleSampler(n_samples, \n",
    "                                        self.input_dim, \n",
    "                                        self.log_prob, args=[y], \n",
    "                                        vectorize = True)\n",
    "        \n",
    "        # Initialize uniformly as the starting point\n",
    "        p0 = np.random.uniform(size = [n_samples, self.input_dim]) * (self.u_high - self.u_low) + self.u_low\n",
    "        \n",
    "        # Get the result\n",
    "        sampler.run_mcmc(p0, self.MCMCsteps)\n",
    "        self.samples = sampler.get_last_sample().coords\n",
    "        \n",
    "        # If there is self_etas, this is to make sure MaxMinDistRatio does not go too large\n",
    "        if len(self.etas) > 0:\n",
    "            eta_times = 0\n",
    "            while (eta_times < 2) and (MaxMinDistRatio(self.samples) > 100.):\n",
    "                # Double the last eta\n",
    "                self.etas[-1] = 2. * self.etas[-1]\n",
    "                eta_times += 1\n",
    "                \n",
    "                # Re-sample\n",
    "                sampler = emcee.EnsembleSampler(n_samples, \n",
    "                                                self.input_dim, \n",
    "                                                self.log_prob, args=[y], \n",
    "                                                vectorize = True)\n",
    "\n",
    "                # Initialize uniformly as the starting point\n",
    "                p0 = np.random.uniform(size = [n_samples, self.input_dim]) * (self.u_high - self.u_low) + self.u_low\n",
    "\n",
    "                # Get the result\n",
    "                sampler.run_mcmc(p0, self.MCMCsteps)\n",
    "                self.samples = sampler.get_last_sample().coords\n",
    "                MCsteps = 0\n",
    "                while (MCsteps < self.MCMCsteps / 10) and (MaxMinDistRatio(self.samples) > 10.):\n",
    "                    sampler.run_mcmc(sampler.get_last_sample(), 1)\n",
    "                    self.samples = sampler.get_last_sample().coords\n",
    "                    MCsteps += 1\n",
    "            \n",
    "            # print(\"eta_times, MaxMinDistRatio: \", eta_times, MaxMinDistRatio(self.samples))\n",
    "\n",
    "\n",
    "        # Run the forward map with the samples\n",
    "        myBatch = RunABatch(self.samples, self.work_path, FourierTerms = self.FourierTerms, \n",
    "                            distanceAbove = self.distanceAbove, nOfQueryPts = self.nOfQueryPts, \n",
    "                            obsFlag = self.obsFlag, fourierFlag = self.fourierFlag)\n",
    "        self.U = np.append(self.U, self.samples, axis = 0)\n",
    "        self.O = np.append(self.O, myBatch.Observations, axis = 0)\n",
    "\n",
    "        # Get a new Gaussian process\n",
    "        myGP = GP_predictor(self.samples, myBatch.Observations)\n",
    "\n",
    "        # Update the recorded variables of the process\n",
    "        self.GPs.append(myGP)\n",
    "        self.iterations += 1\n",
    "        self.etas.append(self.si_eta)\n",
    "        self.avg_errors.append(self.get_avg_error_of_a_batch(myBatch))\n",
    "        self.maxMinDistRatio.append(MaxMinDistRatio(self.samples))\n",
    "        \n",
    "        # Update stats\n",
    "        self.compute_stats(n_stat_samples)\n",
    "        \n",
    "        # Converging flag False\n",
    "        return False\n",
    "    \n",
    "    # Run function\n",
    "    def run(self, n_iter_max = 10, n_stat_samples = 1000):\n",
    "        for i in range(n_iter_max):\n",
    "            # In each iteration\n",
    "            print(\"=\"*30, \" Iteration \", str(self.iterations), \" \", \"=\"*30)\n",
    "            \n",
    "            # Run one iteration\n",
    "            start_time = time.time()\n",
    "            converged = self.runOneIteration(self.n_samples, n_stat_samples)\n",
    "            end_time = time.time()\n",
    "            print(\"Time cost: \", str(end_time - start_time), \" s\")\n",
    "            # print(\"Average error in this iteration: \", self.avg_errors[-1])\n",
    "            print(\"Maximum to minimum distance in the sample points: \", self.maxMinDistRatio[-1])\n",
    "            # print(\"Mean of the posterior after this iteration: \", self.mean[-1])\n",
    "            # print(\"Stdv of the posterior after this iteration: \", self.stdv[-1])\n",
    "            print(\"Max likelihood estimate of the posterior after this iteration: \", self.maxLikelihoodUs[-1])\n",
    "            print(\"L2 error of u: \", self.maxLikelihoodUsPropL2Error[-1])\n",
    "            print(\"L2 error of y: \", self.maxLikelihoodObsPropL2Error[-1])\n",
    "        # Save the current model to files\n",
    "        self.save()\n",
    "        \n",
    "    # Save the model to files\n",
    "    def save(self):\n",
    "        savePath = self.save_path + \"models/A{0}_B{1}_fw{2}_Vw{3}_dist{4}_nOfQPts{5}_eta{6}-{7}-Fourier-{8}.pickle\".format(self.u[0], self.u[1], self.u[2], self.u[3], self.distanceAbove, self.nOfQueryPts, self.si_eta, self.obsFlag, self.fourierFlag)\n",
    "        with open(savePath, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "    \n",
    "    # Plot the regression process into a gif file\n",
    "    def plotGIF(self):\n",
    "        plotSeries(self, self.u, self.y, self.save_path)\n",
    "\n",
    "        \n",
    "# ===================================== Other Auxiliary functions ==========================================\n",
    "# Function MaxMinDistRatio, compute the ratio of maximum to minimum distance among pts, \n",
    "# for the gaussian process to converge with a reasonable length-scaled kernel, \n",
    "# this value should not be too large\n",
    "def MaxMinDistRatio(pts):\n",
    "    matrix = [[np.linalg.norm(pts[i] - pts[j]) for j in range(i + 1, len(pts))] for i in range(len(pts))]\n",
    "    vec = [x for y in matrix for x in y]\n",
    "    return max(vec) / min(vec)\n",
    "\n",
    "\n",
    "# Calculate the corresponding (to y) log likelihood of iter_step on u\n",
    "def log_prob_best(self, iter_step, u, y):\n",
    "    # Apply hard constraints\n",
    "    u_reshape = u.reshape([-1, self.input_dim])\n",
    "    normal_idx = np.all(np.concatenate([u_reshape >= self.u_low, u_reshape <= self.u_high], axis = 1), axis = 1)\n",
    "\n",
    "    # First prior is uniform distribution\n",
    "    res = np.ones(len(u_reshape))\n",
    "    res[~normal_idx] = -np.inf\n",
    "\n",
    "    # Add all posteriors in each iteration\n",
    "    if (np.sum(normal_idx) > 0):\n",
    "        for i in range(iter_step + 1):\n",
    "            res[normal_idx] += -0.5 / self.etas[i] ** 2 * (\n",
    "                np.sum(\n",
    "                    (y - self.GPs[i].predict(u_reshape[normal_idx])) ** 2, \n",
    "                    axis = 1\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Return the log_probability at the current iteration\n",
    "    return res\n",
    "\n",
    "# Plot the given regression process on (analytical_u, analytical_y) and save the GIF\n",
    "def plotSeries(self, analytical_u, analytical_y, save_path, dpi_value = 300):\n",
    "    # Calculate U_plot\n",
    "    minU = self.u_low\n",
    "    maxU = self.u_high\n",
    "    nOfGridPoints = 100\n",
    "\n",
    "    xis = []\n",
    "    for i in range(minU.shape[0]):\n",
    "        xis.append(np.linspace(minU[i], maxU[i], nOfGridPoints))\n",
    "\n",
    "    # Generate grid and draw predictions\n",
    "    UPlotGrid = np.meshgrid(xis[0], xis[1])\n",
    "    UPlotGrid = np.stack(UPlotGrid, axis = 2)\n",
    "    UPlotGridFat = UPlotGrid.reshape([nOfGridPoints * nOfGridPoints, maxU.shape[0]])\n",
    "    \n",
    "    gifName = save_path + \"figures/A{0}_B{1}.gif\".format(analytical_u[0], analytical_u[1])\n",
    "    \n",
    "    writer = imageio.get_writer(gifName, mode='I', duration = 1.0)\n",
    "    \n",
    "    # Maximum likelihood points\n",
    "    self.maxLikelihoodUs = []\n",
    "    self.maxLikelihoodUsPropL2Error = []\n",
    "    self.maxLikelihoodObsPropL2Error = []\n",
    "    \n",
    "    # Plot the series\n",
    "    for i in range(0, self.iterations):\n",
    "        plt.figure(figsize = (7, 6), dpi = dpi_value)\n",
    "        YPlotGridFat = log_prob_best(self, i, UPlotGridFat, analytical_y)\n",
    "        YPlotGridFat = YPlotGridFat - np.max(YPlotGridFat)\n",
    "        \n",
    "        # Get optimized u\n",
    "        idx = np.argmax(YPlotGridFat)\n",
    "        \n",
    "        # self.maxLikelihoodUs.append(UPlotGridFat[idx])\n",
    "        \n",
    "        fun = lambda u: -log_prob_best(self, i, u, analytical_y)\n",
    "        newCenter = opt.minimize(fun, x0 = UPlotGridFat[idx], \n",
    "                                 bounds = [(self.u_low[i], self.u_high[i]) for i in range(len(self.u_low))]\n",
    "                                ).x\n",
    "        \n",
    "        # DEBUG LINES\n",
    "        # print(\"=\" * 60)\n",
    "        # print(\"i, u = \", i, newCenter)\n",
    "        \n",
    "        # print(\"-fun(u_opt), log_prob_best(u_opt): \", -fun(newCenter), log_prob_best(self, i, newCenter, analytical_y))\n",
    "        # print(\"-fun(grid_opt), log_prob_best(grid_opt): \", -fun(UPlotGridFat[idx]), log_prob_best(self, i, UPlotGridFat[idx], analytical_y))\n",
    "        self.maxLikelihoodUs.append(newCenter)\n",
    "        \n",
    "        self.maxLikelihoodUsPropL2Error.append(\n",
    "            np.linalg.norm(analytical_u - self.maxLikelihoodUs[-1]) \n",
    "            / np.linalg.norm(analytical_u)\n",
    "        )\n",
    "        self.maxLikelihoodObsPropL2Error.append(\n",
    "            np.linalg.norm(analytical_y - self.GPs[i].predict(self.maxLikelihoodUs[-1])) \n",
    "            / np.linalg.norm(analytical_y)\n",
    "        )\n",
    "        \n",
    "        YPlotGrid = YPlotGridFat.reshape([nOfGridPoints, nOfGridPoints])\n",
    "        cp = plt.contourf(UPlotGrid[:, :, 0], UPlotGrid[:, :, 1], np.maximum(YPlotGrid, -5.))\n",
    "        \n",
    "        # Give the color bar\n",
    "        cbar = plt.colorbar(cp)\n",
    "        plt.clim([-5., 0.])\n",
    "        cbar.set_label('$-\\\\Phi(u)$', fontsize = 20)\n",
    "        \n",
    "        # Scatter the sample points\n",
    "        plt.scatter(self.U[ :(i + 1) * self.n_samples, 0], \n",
    "                    self.U[ :(i + 1) * self.n_samples, 1], s = 1, color = 'white')\n",
    "        plt.scatter(analytical_u[0], analytical_u[1], s = 15, color = 'red')\n",
    "        plt.xlabel('$u_1$', fontsize = 20)\n",
    "        plt.ylabel('$u_2$', fontsize = 20)\n",
    "        plt.title(\"The \" + str(i) + \" th iteration\")\n",
    "        figName = save_path + \"figures/shit\" + str(i) + \".png\"\n",
    "        plt.savefig(figName, dpi = dpi_value)\n",
    "        \n",
    "        # Save the figures into a gif\n",
    "        image = imageio.imread(figName)\n",
    "        writer.append_data(image)\n",
    "        !rm $figName\n",
    "    writer.close()\n",
    "    \n",
    "    # Save a figure of L2PropError of u\n",
    "    plt.figure(figsize = (7, 6), dpi = dpi_value)\n",
    "    plt.scatter(range(1, 1 + len(self.maxLikelihoodUsPropL2Error)), self.maxLikelihoodUsPropL2Error, s = 20)\n",
    "    plt.xlabel('Iteration', fontsize = 20)\n",
    "    plt.ylabel('$\\|u-u_{true}\\|/\\|u_{true}\\|$', fontsize = 20)\n",
    "    # plt.ylim([0., 0.01])\n",
    "    plt.title('Relative L2 error of $u$', fontsize = 20)\n",
    "    figName = save_path + \"figures/A{0}_B{1}_propL2UError.png\".format(analytical_u[0], analytical_u[1])\n",
    "    plt.savefig(figName, dpi = dpi_value)\n",
    "\n",
    "    # Save a figure of L2PropError of y\n",
    "    plt.figure(figsize = (7, 6), dpi = dpi_value)\n",
    "    plt.scatter(range(1, 1 + len(self.maxLikelihoodUsPropL2Error)), self.maxLikelihoodObsPropL2Error, s = 20)\n",
    "    plt.xlabel('Iteration', fontsize = 20)\n",
    "    plt.ylabel('$\\|y-y_{true}\\|/\\|y_{true}\\|$', fontsize = 20)\n",
    "    # plt.ylim([0., 0.01])\n",
    "    plt.title('Relative L2 error of $y$', fontsize = 20)\n",
    "    figName = save_path + \"figures/A{0}_B{1}_propL2YError.png\".format(analytical_u[0], analytical_u[1])\n",
    "    plt.savefig(figName, dpi = dpi_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "def loadInvModel(model_path):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        myInv = pickle.load(file)\n",
    "    return myInv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shengduo/InverseProblems/GPRWorkingField\r\n"
     ]
    }
   ],
   "source": [
    "# Test run a batch\n",
    "input_set = [[0.016, 0.011, 0.1, 2], [0.016, 0.012, 0.2, 3]]\n",
    "distanceAbove = 1e-3\n",
    "nOfQueryPts = 10\n",
    "fTerms = 16\n",
    "obsFlag = 'everywhere'\n",
    "fourierFlag = False\n",
    "myBatch = RunABatch(input_set, work_path, fTerms, distanceAbove, nOfQueryPts, obsFlag, fourierFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.774530797777208"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myBatch.Observations.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input set:  [(0.016, 0.011, 0.1, 2), (0.016, 0.012, 0.2, 3)]\n",
      "Work path:  /home/shengduo/pylith-developer/build/debug/pylith-nonRegSlipLawWithVaryingB/examples/2d/InverseExp/\n"
     ]
    }
   ],
   "source": [
    "# Generate test batch\n",
    "u_low = np.array([0.010, 0.005, 0.1, 1.])\n",
    "u_high = np.array([0.02, 0.015, 0.5, 5.])\n",
    "nSamples = 10\n",
    "siEta = 1.0\n",
    "print(\"Test input set: \", myBatch.input_set)\n",
    "print(\"Work path: \", work_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================  Iteration  0   ==============================\n",
      "Running case A0.010409733197740358_B0.010568725345686081_fw0.14401655277415354_Vw3.5857374184198427\n",
      "Finished in 98 s!\n",
      "\n",
      "Running case A0.018556215899525427_B0.0076266718347148075_fw0.18829625568827146_Vw3.007926874756835\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.019473007747747816_B0.007275963469422996_fw0.48607252359422337_Vw1.4373871122496016\n",
      "Finished in 94 s!\n",
      "\n",
      "Running case A0.017951768449466846_B0.006183281207138417_fw0.30400123900785414_Vw4.797511384773941\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.01823646683660993_B0.010403444546260118_fw0.23501181817870298_Vw2.1786085623797797\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.016937355209089122_B0.008322624349537643_fw0.3025355123596848_Vw4.096252529526033\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.016254137711575724_B0.00620719034395281_fw0.24772874705661777_Vw1.8807859997661271\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.017456991968861125_B0.005301735926740364_fw0.4683866589948496_Vw1.9098287084543482\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.0119635785057985_B0.009808735404604745_fw0.3677602804570982_Vw3.968812775426115\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.012018517644914246_B0.01311199784310331_fw0.45000928971502385_Vw1.0790048201792417\n",
      "Finished in 97 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  966.8742153644562  s\n",
      "Maximum to minimum distance in the sample points:  2.597726356974895e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01495786 0.00999109 0.30096025 2.99504184]\n",
      "L2 error of u:  0.5069094952366705\n",
      "L2 error of y:  0.6712578742226591\n",
      "==============================  Iteration  1   ==============================\n",
      "Running case A1.9775596771250604e-02_B0.0057728656473946365_fw0.44404138862272685_Vw4.587234947130162\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.01740580904374866_B0.006971701197854535_fw0.4750556777479448_Vw3.679612203166627\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.016764928744018054_B0.012032765463998328_fw0.27194347378593825_Vw3.2764352119006235\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.01815521036803132_B0.01185702188836956_fw0.4817754690938563_Vw2.3896093227857254\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.019601856280080474_B0.008414220876875027_fw0.47247700379132507_Vw4.084311894072732\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.011596065785900096_B0.012901250506773581_fw0.16478938631619142_Vw2.2691674110886515\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.014950619097968382_B0.008783698942525578_fw0.40519922177312484_Vw4.568307569355199\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.01533228532152509_B0.0051775317041741434_fw0.22652802055861493_Vw4.072351520763695\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.015131185634559192_B0.008604542561296039_fw0.21120213564347937_Vw1.4770332116817055\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.019726848267327977_B0.005508343766725452_fw0.41831116102706967_Vw2.36933915320618\n",
      "Finished in 97 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  965.259265422821  s\n",
      "Maximum to minimum distance in the sample points:  7.156578746908951e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01610289 0.00953876 0.23740657 1.85121669]\n",
      "L2 error of u:  0.10113486713434865\n",
      "L2 error of y:  0.6209493779666337\n",
      "==============================  Iteration  2   ==============================\n",
      "Running case A1.5796076580636517e-02_B0.006410122102932646_fw0.2086753579178686_Vw1.7638537313277545\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.014906892336831064_B0.006021294181600353_fw0.20545167197850644_Vw1.3640493176109298\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.014934367179101907_B0.006902652448227692_fw0.18111946884266625_Vw1.7196488195201272\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.014616366107519194_B0.00842103825409855_fw0.2510670820824909_Vw2.3067564092721726\n",
      "Finished in 98 s!\n",
      "\n",
      "Running case A0.01655486174683613_B0.007545947519141603_fw0.19196296386533118_Vw1.1962520873419702\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.015177211658833243_B0.007777017303183187_fw0.24881161640447733_Vw1.0325988612380452\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.01682129845730301_B0.009469672838326023_fw0.23307230454084407_Vw1.5172762156519994\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.016908764190440656_B0.008560553229156453_fw0.1605455153071937_Vw1.1671666498024964\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.016168636825718403_B0.007610925847811361_fw0.20051680834936778_Vw1.8381503639945038\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.014340196215365458_B0.007370553526831262_fw0.26762952240917104_Vw1.1501685406358986\n",
      "Finished in 92 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  948.2340035438538  s\n",
      "Maximum to minimum distance in the sample points:  2.9751146822332636e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01675604 0.00865212 0.18267629 1.54352491]\n",
      "L2 error of u:  0.23165388972133322\n",
      "L2 error of y:  0.3546295974306264\n",
      "==============================  Iteration  3   ==============================\n",
      "Running case A0.016197537654838907_B0.00842346429074952_fw0.2610887169971868_Vw2.2266798117979105\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016575657223326476_B0.00825563924842168_fw0.18846604821899204_Vw1.9852443905930108\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016348544548439623_B0.008711179248069856_fw0.12855173279693222_Vw1.1058658867517503\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.019923478732873992_B0.014774194087466726_fw0.4688188042358718_Vw4.6312171324698435\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.015879432085321186_B0.008120725536209655_fw0.14041725324611362_Vw1.2782727176492168\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.015764965744595447_B0.00740824564102576_fw0.21225543656413792_Vw1.9505650847795206\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.011849430104575797_B0.007476105914170585_fw0.17056799056705713_Vw1.5993369727290194\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.01732163904762546_B0.008433784781488835_fw0.18219659083435263_Vw1.7525708389820813\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.015399260391540354_B0.007779519637539287_fw0.2668205170769363_Vw2.0684054810604273\n",
      "Finished in 98 s!\n",
      "\n",
      "Running case A0.015423789601601512_B0.007498820778545412_fw0.22673832872335767_Vw1.877372555943479\n",
      "Finished in 98 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  977.8158767223358  s\n",
      "Maximum to minimum distance in the sample points:  8.418497219274676e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.0156413  0.00748874 0.22731099 1.87265903]\n",
      "L2 error of u:  0.08993377894106257\n",
      "L2 error of y:  0.44119028375020886\n",
      "==============================  Iteration  4   ==============================\n",
      "Running case A1.6340458325979027e-02_B0.008464071928826717_fw0.20899449583719448_Vw1.702440054507821\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.015217273972218608_B0.007480096483401818_fw0.233924085371073_Vw1.832381415432276\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.017583173219538614_B0.009870768472900908_fw0.18646990421132312_Vw1.2466906659257604\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.01615856254605852_B0.00849405285807068_fw0.20317250128868772_Vw1.616317383651352\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.016798932819564242_B0.008358214823867527_fw0.19424313557955225_Vw1.5994977467673392\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.01569658455451166_B0.0067320065017920615_fw0.23097883461014412_Vw1.7524796075279623\n",
      "Finished in 98 s!\n",
      "\n",
      "Running case A0.01622775273857043_B0.008322017835407468_fw0.23211064121344177_Vw1.7181213301179739\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.01612931296740715_B0.01004657684139357_fw0.16705821785538263_Vw1.120905361751128\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.015605643919381063_B0.00872823714471967_fw0.2999434948278938_Vw1.1020537649943818\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.015359298323566584_B0.0073568473590611425_fw0.22639783137450845_Vw1.7311473812706841\n",
      "Finished in 93 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  971.894278049469  s\n",
      "Maximum to minimum distance in the sample points:  5.134174341716198e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01627737 0.00857602 0.18876208 1.50246218]\n",
      "L2 error of u:  0.2523725500211151\n",
      "L2 error of y:  0.28662695005453803\n",
      "==============================  Iteration  5   ==============================\n",
      "Running case A1.6189153960903358e-02_B0.008614117634905757_fw0.18673722835855486_Vw1.4272172505984932\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.016290091945826136_B0.00900061225607137_fw0.21185257897510104_Vw1.4848141882353452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 98 s!\n",
      "\n",
      "Running case A0.016163719389826598_B0.008147336895595717_fw0.19378035185308357_Vw1.491211243842878\n",
      "Finished in 93 s!\n",
      "\n",
      "Running case A0.016311127371318332_B0.008742438569546538_fw0.19202338523292298_Vw1.495595567118315\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.015989385992804833_B0.008784552935664994_fw0.18224301059693646_Vw1.5036268912124404\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.01638201580203568_B0.008634247950166742_fw0.1993084551677037_Vw1.4043934885953746\n",
      "Finished in 97 s!\n",
      "\n",
      "Running case A0.01639773066400831_B0.008506335194738496_fw0.19036704194609763_Vw1.469943045537291\n",
      "Finished in 93 s!\n",
      "\n",
      "Running case A0.0161746310903457_B0.008372668065450976_fw0.19188889977869858_Vw1.5187021181250535\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.01640220106664715_B0.008532763348752298_fw0.19080396121091076_Vw1.4584738778299553\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016404840932088566_B0.008905809017180969_fw0.1890854308482204_Vw1.513607788974015\n",
      "Finished in 89 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  954.9927842617035  s\n",
      "Maximum to minimum distance in the sample points:  2.4050464612951533e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01636751 0.00875167 0.18821698 1.49613776]\n",
      "L2 error of u:  0.2554346872976106\n",
      "L2 error of y:  0.2309895031099647\n",
      "==============================  Iteration  6   ==============================\n",
      "Running case A1.6421429537986153e-02_B0.008733755366661228_fw0.1897227804041203_Vw1.4413885082073354\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016355311720753347_B0.008643946846855129_fw0.18999378185276458_Vw1.5135671376047661\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.016323373140860187_B0.008662973927135042_fw0.18537446833250204_Vw1.4822974665544582\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.01638579048584739_B0.008797089109155162_fw0.18930709743988786_Vw1.4978112191669424\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.016323362120314554_B0.008716964594959192_fw0.1860151689272077_Vw1.5266892043946625\n",
      "Finished in 93 s!\n",
      "\n",
      "Running case A0.01637667812456941_B0.008591259323525533_fw0.18747779657842542_Vw1.5709425539878017\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.0163672337551905_B0.00842748265814708_fw0.18925406731831212_Vw1.5043926395588563\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016093838429412675_B0.009064496835001972_fw0.19883812845603321_Vw1.6115318014567515\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.01634211191671714_B0.008859790388240734_fw0.18393020490594275_Vw1.516042163667856\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016321672439434616_B0.008738746188739219_fw0.18843320974216574_Vw1.5431546591005405\n",
      "Finished in 89 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  943.3293144702911  s\n",
      "Maximum to minimum distance in the sample points:  2.6002219770485976e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01637061 0.00883638 0.18569196 1.49546264]\n",
      "L2 error of u:  0.2555524349243086\n",
      "L2 error of y:  0.21625027617373743\n",
      "==============================  Iteration  7   ==============================\n",
      "Running case A1.6301806072971783e-02_B0.008861788904189255_fw0.1896117765032788_Vw1.513894672495448\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.01624803558470445_B0.008742948599357857_fw0.19502438701927816_Vw1.480665894256929\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016363656281879836_B0.008671807878484756_fw0.1907031808730319_Vw1.518423109121675\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016388684524207622_B0.008657152869146076_fw0.19190627728149026_Vw1.4770421124758344\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016405993316333693_B0.008676580177081773_fw0.19155208503219506_Vw1.4924569780602888\n",
      "Finished in 99 s!\n",
      "\n",
      "Running case A0.016344940688106442_B0.008657284588026757_fw0.1913389986185776_Vw1.4862699485814368\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016241893918683567_B0.008825769391574867_fw0.1874438094384985_Vw1.4963517983491486\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.016392280007084342_B0.008661669393054067_fw0.18520078767087547_Vw1.4729781765582681\n",
      "Finished in 92 s!\n",
      "\n",
      "Running case A0.016311841544973164_B0.00893888173721814_fw0.18864070738001817_Vw1.5036208277582712\n",
      "Finished in 91 s!\n",
      "\n",
      "Running case A0.01629354789775193_B0.008790805450013442_fw0.1845260297505307_Vw1.4918033590174165\n",
      "Finished in 99 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  962.4428753852844  s\n",
      "Maximum to minimum distance in the sample points:  9.818334469320838e+00\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01637837 0.00884249 0.18620671 1.4912824 ]\n",
      "L2 error of u:  0.2576534061245051\n",
      "L2 error of y:  0.21840628310103405\n",
      "==============================  Iteration  8   ==============================\n",
      "Running case A1.6423471433560773e-02_B0.008993956341021153_fw0.19508726944423066_Vw1.4901104283323405\n",
      "Finished in 93 s!\n",
      "\n",
      "Running case A0.015223665210587604_B0.008813919573437738_fw0.2848054820372622_Vw1.720315067030762\n",
      "Finished in 94 s!\n",
      "\n",
      "Running case A0.016455258044641794_B0.008824579173620839_fw0.1898703205939731_Vw1.459529053758129\n",
      "Finished in 96 s!\n",
      "\n",
      "Running case A0.016279404023918614_B0.008988175553172325_fw0.18726696926194694_Vw1.5423730240680957\n",
      "Finished in 89 s!\n",
      "\n",
      "Running case A0.01627242847873332_B0.008685633882827386_fw0.18459159072005038_Vw1.56476009319436\n",
      "Finished in 89 s!\n",
      "\n",
      "Running case A0.016427979060029185_B0.008331729911540919_fw0.18835046296081687_Vw1.4125343610847436\n",
      "Finished in 88 s!\n",
      "\n",
      "Running case A0.016386516331477623_B0.008527017099337255_fw0.19371185228098353_Vw1.4875321751390689\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016351399779436924_B0.008573839291326551_fw0.19735591447275952_Vw1.3972369858000453\n",
      "Finished in 89 s!\n",
      "\n",
      "Running case A0.016436587473651305_B0.008919959090938146_fw0.1873842890942035_Vw1.4864533925529342\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016326293891214073_B0.008928725696168828_fw0.186354450294595_Vw1.4951433362137405\n",
      "Finished in 87 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  943.4156925678253  s\n",
      "Maximum to minimum distance in the sample points:  1.1309602315691605e+02\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01638898 0.00888886 0.18777288 1.48448719]\n",
      "L2 error of u:  0.26112954337578875\n",
      "L2 error of y:  0.20826573839480286\n",
      "==============================  Iteration  9   ==============================\n",
      "Running case A1.6420366225215657e-02_B0.00887540030905898_fw0.18654834108204127_Vw1.4933349741271027\n",
      "Finished in 88 s!\n",
      "\n",
      "Running case A0.016378765452585525_B0.008887301880979904_fw0.19020513679606488_Vw1.4796900863440654\n",
      "Finished in 88 s!\n",
      "\n",
      "Running case A0.01646872326197301_B0.008843137203976037_fw0.19058033214221518_Vw1.4599151728587834\n",
      "Finished in 88 s!\n",
      "\n",
      "Running case A0.01640229740228541_B0.00878407183686405_fw0.1897992943081876_Vw1.4876807567363495\n",
      "Finished in 89 s!\n",
      "\n",
      "Running case A0.016373864832725717_B0.008847112817099528_fw0.19079976304795046_Vw1.4851099007529651\n",
      "Finished in 88 s!\n",
      "\n",
      "Running case A0.01629080829262139_B0.008865909192134529_fw0.19065461520551633_Vw1.5569238192390462\n",
      "Finished in 90 s!\n",
      "\n",
      "Running case A0.016391899613061502_B0.008892214858800573_fw0.18810590536225893_Vw1.5007508116907484\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.01637684531388153_B0.00877868123035316_fw0.19360087245868607_Vw1.4769867470806761\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.016422882503202018_B0.008878800762301775_fw0.18625438132017252_Vw1.4677901990320334\n",
      "Finished in 95 s!\n",
      "\n",
      "Running case A0.01635998154919265_B0.008833331790148382_fw0.18804847641134734_Vw1.5252429599108845\n",
      "Finished in 96 s!\n",
      "\n",
      "/home/shengduo/InverseProblems/GPRWorkingField\n",
      "Time cost:  940.9042978286743  s\n",
      "Maximum to minimum distance in the sample points:  3.515408256815535e+01\n",
      "Max likelihood estimate of the posterior after this iteration:  [0.01641286 0.00887833 0.18674228 1.47842535]\n",
      "L2 error of u:  0.26402917031691436\n",
      "L2 error of y:  0.20641551404409889\n"
     ]
    }
   ],
   "source": [
    "# Run an inversion test:\n",
    "testCase_idx = 1\n",
    "u = myBatch.input_set[testCase_idx]\n",
    "y = myBatch.Observations[testCase_idx]\n",
    "myInv = BayersianInv(u_low, u_high, u, y, work_path, FourierTerms = fTerms, \n",
    "                     n_samples = nSamples, si_eta = siEta, nOfQueryPts = nOfQueryPts, \n",
    "                     distanceAbove = distanceAbove, obsFlag = obsFlag, fourierFlag = fourierFlag)\n",
    "myInv.run(n_iter_max = 10)\n",
    "\n",
    "# # Save to file\n",
    "# import pickle\n",
    "\n",
    "# #save it\n",
    "# with open(f'./models/myInvA4_B6.pickle', 'wb') as file:\n",
    "#     pickle.dump(myInv, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shengduo/InverseProblems/GPRWorkingField\r\n"
     ]
    }
   ],
   "source": [
    "# Test observations\n",
    "# Test run a batch\n",
    "input_set = [[0.016, 0.011, 0.1, 2], [0.016, 0.012, 0.2, 3]]\n",
    "distanceAbove = 1e-3\n",
    "nOfQueryPts = 10\n",
    "fTerms = 16\n",
    "obsFlag = 'frontsurf'\n",
    "myBatch = RunABatch(input_set, work_path, fTerms, distanceAbove, nOfQueryPts, obsFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.169259194698046e-06"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCase_idx = 0\n",
    "u = myBatch.input_set[testCase_idx]\n",
    "y = myBatch.Observations[testCase_idx]\n",
    "np.linalg.norm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test open an h5 file\n",
    "nOfQueryPts = 10\n",
    "\n",
    "# Rotation matrix Q\n",
    "alpha = 29 / 180 * np.pi\n",
    "Q = np.array([[np.cos(alpha), np.sin(alpha)], [-np.sin(alpha), np.cos(alpha)]])\n",
    "\n",
    "# VS start\n",
    "VSstart = np.array([0.006354, 0.003522])\n",
    "\n",
    "# Query points\n",
    "distance_above = distanceAbove  # Distance above the interface\n",
    "\n",
    "# Set x_up query points\n",
    "x_up = 1e-3 * np.linspace(0., 45., nOfQueryPts)\n",
    "QueryPts_up = np.stack([x_up, distance_above * np.ones(x_up.shape)], axis = 1)\n",
    "QueryPts_dn = np.stack([x_up, -distance_above * np.ones(x_up.shape)], axis = 1)\n",
    "\n",
    "# nOfNodes\n",
    "nOfNodes = len(x_up)\n",
    "        \n",
    "\n",
    "# Open the file\n",
    "# h5_file = \"/home/shengduo/pylith-developer/build/debug/pylith-nonRegSlipLawWithVaryingB/examples/2d/InverseExp/output/frontsurfFiles/A0.016_B0.011_fw0.1_Vw2-domain.h5\"\n",
    "h5_file = \"/home/shengduo/pylith-developer/build/debug/pylith-nonRegSlipLawWithVaryingB/examples/2d/InverseExp/output/frontsurfFiles/A0.016_B0.012_fw0.2_Vw3-domain.h5\"\n",
    "\n",
    "f = h5py.File(h5_file, 'r')\n",
    "\n",
    "# Get time\n",
    "times = np.array(f['time']).reshape([-1])\n",
    "times = times - np.min(times)\n",
    "nOfTSteps = times.shape[0]\n",
    "times = times / np.max(times)\n",
    "\n",
    "# Get coordinates\n",
    "coords = np.array(f['geometry']['vertices']) - VSstart\n",
    "Qcoords = coords @ Q.transpose()\n",
    "\n",
    "# Store the slip rates\n",
    "slip_rate_x = np.zeros([nOfTSteps, nOfNodes])\n",
    "\n",
    "# Get Slip rates\n",
    "velocity = np.array(f['vertex_fields']['velocity'])\n",
    "Qvelocity = velocity @ Q.transpose()\n",
    "\n",
    "for i in range(nOfTSteps):\n",
    "    slip_rate_x[i, :] = - griddata(Qcoords, velocity[i, :, 0], QueryPts_up, method = 'cubic') \\\n",
    "                  + griddata(Qcoords, velocity[i, :, 0], QueryPts_dn, method = 'cubic')\n",
    "slip_rate_x = slip_rate_x.transpose()\n",
    "\n",
    "# Find the Fourier coefficients\n",
    "FourierTerms = 32\n",
    "T = np.max(times)\n",
    "\n",
    "# Compute the Fourier terms\n",
    "Ks = np.array(range(FourierTerms))\n",
    "coskPiTt = np.cos(Ks.reshape([-1, 1]) * np.pi / T * times)\n",
    "VxcoskPiTt = np.concatenate([coskPiTt * Vxi.reshape([1, -1]) for Vxi in slip_rate_x], 0)\n",
    "\n",
    "# Compute the fourier coefficients\n",
    "# print('time.shape: ', time.shape)\n",
    "observation = np.trapz(VxcoskPiTt, x=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26449251741463475"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(slip_rate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01001001, 0.02102102, 0.03203203, 0.04304304,\n",
       "       0.05405405, 0.06506507, 0.07607608, 0.08608609, 0.0960961 ,\n",
       "       0.10610611, 0.11611612, 0.12612613, 0.13613614, 0.14614615,\n",
       "       0.15615616, 0.16716717, 0.17817818, 0.18918919, 0.2002002 ,\n",
       "       0.21121121, 0.22222222, 0.23323323, 0.24424424, 0.25525526,\n",
       "       0.26626627, 0.27727728, 0.28828829, 0.2992993 , 0.30930931,\n",
       "       0.31931932, 0.32932933, 0.33933934, 0.34934935, 0.35935936,\n",
       "       0.36936937, 0.37937938, 0.38938939, 0.3993994 , 0.40940941,\n",
       "       0.41941942, 0.42942943, 0.43943944, 0.44944945, 0.45945946,\n",
       "       0.46946947, 0.47947948, 0.48948949, 0.4994995 , 0.50950951,\n",
       "       0.51951952, 0.52952953, 0.53953954, 0.54954955, 0.55955956,\n",
       "       0.56956957, 0.57957958, 0.58958959, 0.5995996 , 0.60960961,\n",
       "       0.61961962, 0.62962963, 0.63963964, 0.64964965, 0.65965966,\n",
       "       0.66966967, 0.67967968, 0.68968969, 0.6996997 , 0.70970971,\n",
       "       0.71971972, 0.72972973, 0.73973974, 0.74974975, 0.75975976,\n",
       "       0.76976977, 0.77977978, 0.78978979, 0.7997998 , 0.80980981,\n",
       "       0.81981982, 0.82982983, 0.83983984, 0.84984985, 0.85985986,\n",
       "       0.86986987, 0.87987988, 0.88988989, 0.8998999 , 0.90990991,\n",
       "       0.91991992, 0.92992993, 0.93993994, 0.94994995, 0.95995996,\n",
       "       0.96996997, 0.97997998, 0.98998999, 1.        ])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044417879449190616"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09185036106914132"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ True,  True,  True,  True]), array([ True,  True,  True,  True])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u >= myInv.u_low, u <= myInv.u_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
